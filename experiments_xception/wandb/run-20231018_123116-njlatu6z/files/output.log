
Epoch: 1/50
TRAIN [ 100/2250] Loss: 0.2351 (0.3960) Acc: 82.125% LR: 1.000e-03 Time: 0.380s,   84.27/s (0.444s,   71.99/s) Data: 0.007 (0.018)
TRAIN [ 200/2250] Loss: 0.4847 (0.3197) Acc: 86.094% LR: 1.000e-03 Time: 0.379s,   84.41/s (0.413s,   77.46/s) Data: 0.007 (0.013)
TRAIN [ 300/2250] Loss: 0.1768 (0.2799) Acc: 88.177% LR: 1.000e-03 Time: 0.381s,   83.91/s (0.402s,   79.55/s) Data: 0.006 (0.011)
TRAIN [ 400/2250] Loss: 0.3196 (0.2480) Acc: 89.641% LR: 1.000e-03 Time: 0.380s,   84.19/s (0.397s,   80.52/s) Data: 0.006 (0.010)
TRAIN [ 500/2250] Loss: 0.1627 (0.2270) Acc: 90.631% LR: 1.000e-03 Time: 0.381s,   83.88/s (0.395s,   81.11/s) Data: 0.007 (0.010)
TRAIN [ 600/2250] Loss: 0.4439 (0.2124) Acc: 91.276% LR: 1.000e-03 Time: 0.389s,   82.34/s (0.392s,   81.56/s) Data: 0.007 (0.009)
TRAIN [ 700/2250] Loss: 0.0404 (0.1992) Acc: 91.911% LR: 1.000e-03 Time: 0.386s,   82.86/s (0.391s,   81.82/s) Data: 0.006 (0.009)
TRAIN [ 800/2250] Loss: 0.0647 (0.1882) Acc: 92.355% LR: 1.000e-03 Time: 0.382s,   83.71/s (0.390s,   82.08/s) Data: 0.006 (0.009)
TRAIN [ 900/2250] Loss: 0.1114 (0.1767) Acc: 92.906% LR: 1.000e-03 Time: 0.388s,   82.49/s (0.389s,   82.20/s) Data: 0.007 (0.009)
TRAIN [1000/2250] Loss: 0.0332 (0.1694) Acc: 93.200% LR: 1.000e-03 Time: 0.385s,   83.14/s (0.389s,   82.35/s) Data: 0.006 (0.009)
TRAIN [1100/2250] Loss: 0.1300 (0.1626) Acc: 93.503% LR: 1.000e-03 Time: 0.389s,   82.17/s (0.388s,   82.47/s) Data: 0.009 (0.009)
TRAIN [1200/2250] Loss: 0.0493 (0.1552) Acc: 93.812% LR: 1.000e-03 Time: 0.387s,   82.64/s (0.388s,   82.54/s) Data: 0.006 (0.008)
TRAIN [1300/2250] Loss: 0.1189 (0.1503) Acc: 94.034% LR: 1.000e-03 Time: 0.384s,   83.41/s (0.387s,   82.65/s) Data: 0.008 (0.008)
TRAIN [1400/2250] Loss: 0.1746 (0.1435) Acc: 94.310% LR: 1.000e-03 Time: 0.389s,   82.25/s (0.387s,   82.70/s) Data: 0.007 (0.008)
TRAIN [1500/2250] Loss: 0.0538 (0.1403) Acc: 94.481% LR: 1.000e-03 Time: 0.385s,   83.19/s (0.387s,   82.76/s) Data: 0.006 (0.008)
TRAIN [1600/2250] Loss: 0.1280 (0.1356) Acc: 94.693% LR: 1.000e-03 Time: 0.379s,   84.36/s (0.386s,   82.80/s) Data: 0.006 (0.008)
TRAIN [1700/2250] Loss: 0.0361 (0.1314) Acc: 94.881% LR: 1.000e-03 Time: 0.380s,   84.29/s (0.386s,   82.85/s) Data: 0.007 (0.008)
TRAIN [1800/2250] Loss: 0.1707 (0.1280) Acc: 95.030% LR: 1.000e-03 Time: 0.383s,   83.66/s (0.386s,   82.87/s) Data: 0.007 (0.008)
TRAIN [1900/2250] Loss: 0.0128 (0.1240) Acc: 95.184% LR: 1.000e-03 Time: 0.389s,   82.20/s (0.386s,   82.90/s) Data: 0.007 (0.008)
TRAIN [2000/2250] Loss: 0.0655 (0.1203) Acc: 95.331% LR: 1.000e-03 Time: 0.380s,   84.12/s (0.386s,   82.96/s) Data: 0.007 (0.008)
TRAIN [2100/2250] Loss: 0.0089 (0.1176) Acc: 95.429% LR: 1.000e-03 Time: 0.395s,   81.06/s (0.386s,   83.01/s) Data: 0.007 (0.008)
TRAIN [2200/2250] Loss: 0.0552 (0.1157) Acc: 95.526% LR: 1.000e-03 Time: 0.353s,   90.58/s (0.383s,   83.55/s) Data: 0.006 (0.008)
TEST [101/435]: Loss: 0.114 | Acc: 95.637% [3091/3232]
TEST [201/435]: Loss: 0.134 | Acc: 94.527% [6080/6432]
TEST [301/435]: Loss: 0.121 | Acc: 95.193% [9169/9632]
TEST [401/435]: Loss: 0.121 | Acc: 95.129% [12207/12832]
Best Accuracy 0.000% to 94.381%
Epoch: 2/50
TRAIN [ 100/2250] Loss: 0.3018 (0.0465) Acc: 98.500% LR: 1.000e-03 Time: 0.394s,   81.26/s (0.400s,   79.92/s) Data: 0.007 (0.025)
Traceback (most recent call last):
  File "main.py", line 113, in <module>
    run(cfg)
  File "main.py", line 94, in run
    device       = device)
  File "/home/inho/df_detection/experiments_xception/train.py", line 158, in fit
    train_metrics = train(model, trainloader, criterion, optimizer, log_interval, device)
  File "/home/inho/df_detection/experiments_xception/train.py", line 53, in train
    optimizer.step()
  File "/home/inho/anaconda3/envs/df_detection/lib/python3.7/site-packages/torch/optim/lr_scheduler.py", line 68, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/inho/anaconda3/envs/df_detection/lib/python3.7/site-packages/torch/optim/optimizer.py", line 140, in wrapper
    out = func(*args, **kwargs)
  File "/home/inho/anaconda3/envs/df_detection/lib/python3.7/site-packages/torch/optim/optimizer.py", line 23, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/inho/anaconda3/envs/df_detection/lib/python3.7/site-packages/torch/optim/adam.py", line 252, in step
    found_inf=found_inf)
  File "/home/inho/anaconda3/envs/df_detection/lib/python3.7/site-packages/torch/optim/adam.py", line 316, in adam
    found_inf=found_inf)
  File "/home/inho/anaconda3/envs/df_detection/lib/python3.7/site-packages/torch/optim/adam.py", line 410, in _single_tensor_adam
    denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)
KeyboardInterrupt